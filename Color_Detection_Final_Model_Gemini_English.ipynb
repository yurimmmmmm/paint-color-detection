{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-generativeai==0.3.1"
      ],
      "metadata": {
        "id": "gU_lMod0ms3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "import requests\n",
        "import json\n",
        "from IPython.display import display, HTML, Image\n",
        "import time\n",
        "import re\n",
        "from PIL import Image as PILImage\n",
        "from io import BytesIO\n",
        "\n",
        "\n",
        "import google.generativeai as genai\n"
      ],
      "metadata": {
        "id": "YJJwXc8nmkBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive 마운트\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "PbUNDrCTmq7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Input from User"
      ],
      "metadata": {
        "id": "Fb8tJkuymwcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter Gemini API key\n",
        "GEMINI_API_KEY = input('Enter Gemini API:')\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Model-related classes and functions\n",
        "class ColorDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32) if y is not None else None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.y is not None:\n",
        "            return self.X[idx], self.y[idx]\n",
        "        return self.X[idx]\n",
        "\n",
        "# Function to create dynamic encoder layers\n",
        "def create_encoder_layers(input_dim, hidden_dims, dropout_rate):\n",
        "    layers = []\n",
        "    in_features = input_dim\n",
        "    for hidden_dim in hidden_dims:\n",
        "        layers.append(nn.Linear(in_features, hidden_dim))\n",
        "        layers.append(nn.BatchNorm1d(hidden_dim))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(dropout_rate))\n",
        "        in_features = hidden_dim\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def create_decoder_layers(latent_dim, hidden_dims, output_dim, dropout_rate):\n",
        "    layers = []\n",
        "    in_features = latent_dim\n",
        "    for hidden_dim in hidden_dims:\n",
        "        layers.append(nn.Linear(in_features, hidden_dim))\n",
        "        layers.append(nn.BatchNorm1d(hidden_dim))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(dropout_rate))\n",
        "        in_features = hidden_dim\n",
        "    # Add output layer\n",
        "    layers.append(nn.Linear(in_features, output_dim))\n",
        "    layers.append(nn.Sigmoid())  # Output in 0~1 range\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# AutoEncoder model class\n",
        "class ColorAutoEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, encoder_hidden_dims, latent_dim, decoder_hidden_dims, output_dim, dropout_rate):\n",
        "        super(ColorAutoEncoder, self).__init__()\n",
        "\n",
        "        # Create encoder\n",
        "        self.encoder_layers = create_encoder_layers(input_dim, encoder_hidden_dims, dropout_rate)\n",
        "        self.latent_layer = nn.Linear(encoder_hidden_dims[-1], latent_dim)\n",
        "        self.latent_activation = nn.ReLU()\n",
        "\n",
        "        # Create decoder\n",
        "        self.decoder = create_decoder_layers(latent_dim, decoder_hidden_dims, output_dim, dropout_rate)\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.encoder_layers(x)\n",
        "        latent = self.latent_activation(self.latent_layer(x))\n",
        "        return latent\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent = self.encode(x)\n",
        "        output = self.decoder(latent)\n",
        "        return output\n",
        "\n",
        "# Function to load trained model\n",
        "def load_model(model_path, scaler_path, device='cpu'):\n",
        "    \"\"\"Load the trained model and scalers.\"\"\"\n",
        "    # Load scalers\n",
        "    with open(scaler_path, 'rb') as f:\n",
        "        scalers = pickle.load(f)\n",
        "    X_scaler = scalers['X_scaler']\n",
        "    y_scaler = scalers['y_scaler']\n",
        "\n",
        "    # Load model checkpoint\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    model_params = checkpoint['model_params']\n",
        "\n",
        "    # Extract model configuration parameters\n",
        "    latent_dim = model_params['lat']\n",
        "    encoder_layers = model_params['enc']\n",
        "    decoder_layers = model_params['dec']\n",
        "    dropout_rate = model_params['drop'] / 100.0\n",
        "\n",
        "    # Configure hidden layers\n",
        "    encoder_hidden_dims = [128, 64] if encoder_layers == 2 else [128, 64, 32]\n",
        "    decoder_hidden_dims = [64, 128] if decoder_layers == 2 else [32, 64, 128]\n",
        "\n",
        "    # Initialize model\n",
        "    input_dim = 12  # 4 colors * RGB\n",
        "    output_dim = 3  # RGB\n",
        "\n",
        "    model = ColorAutoEncoder(\n",
        "        input_dim,\n",
        "        encoder_hidden_dims,\n",
        "        latent_dim,\n",
        "        decoder_hidden_dims,\n",
        "        output_dim,\n",
        "        dropout_rate\n",
        "    )\n",
        "\n",
        "    # Load saved weights\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    return model, X_scaler, y_scaler\n",
        "\n",
        "# Function to predict color\n",
        "def predict_color(model, X_scaler, y_scaler, input_values, device='cpu'):\n",
        "    \"\"\"Predict color based on input values.\"\"\"\n",
        "    # Check input format\n",
        "    if isinstance(input_values, list) and len(input_values) == 12:\n",
        "        input_array = np.array([input_values])\n",
        "    elif isinstance(input_values, np.ndarray) and input_values.shape[-1] == 12:\n",
        "        if input_values.ndim == 1:\n",
        "            input_array = input_values.reshape(1, -1)\n",
        "        else:\n",
        "            input_array = input_values\n",
        "    else:\n",
        "        raise ValueError(\"Input must be a list with 12 values or a numpy array of shape (N, 12).\")\n",
        "\n",
        "    # Scale input\n",
        "    input_scaled = X_scaler.transform(input_array)\n",
        "    input_tensor = torch.tensor(input_scaled, dtype=torch.float32).to(device)\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        output_scaled = model(input_tensor).cpu().numpy()\n",
        "\n",
        "    # Inverse scaling\n",
        "    output = y_scaler.inverse_transform(output_scaled)\n",
        "\n",
        "    return output\n",
        "\n",
        "# Function to visualize color prediction\n",
        "def visualize_prediction(input_values, predicted_color, title=None):\n",
        "    \"\"\"Visualize the predicted color.\"\"\"\n",
        "    # Clip RGB values to 0-255 range\n",
        "    predicted_rgb = np.clip(predicted_color[0], 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Normalize RGB values to 0-1 range\n",
        "    predicted_rgb_norm = predicted_rgb / 255.0\n",
        "\n",
        "    # Visualization\n",
        "    fig, ax = plt.subplots(figsize=(6, 3))\n",
        "    ax.add_patch(plt.Rectangle((0, 0), 1, 1, color=predicted_rgb_norm))\n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    else:\n",
        "        plt.title(f\"Predicted Color RGB: ({predicted_rgb[0]}, {predicted_rgb[1]}, {predicted_rgb[2]})\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return predicted_rgb\n",
        "\n",
        "# Function to convert RGB to HEX\n",
        "def rgb_to_hex(rgb):\n",
        "    return '#{:02x}{:02x}{:02x}'.format(int(rgb[0]), int(rgb[1]), int(rgb[2]))\n",
        "\n",
        "# Function to find matching Valspar colors using Gemini API\n",
        "def find_valspar_color(rgb_values):\n",
        "    \"\"\"\n",
        "    Use Gemini API to find closest matching Valspar colors.\n",
        "    \"\"\"\n",
        "    # Convert RGB values to HEX code\n",
        "    hex_color = rgb_to_hex(rgb_values)\n",
        "\n",
        "    # Set up Gemini model\n",
        "    model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "    # Create prompt\n",
        "    prompt = f\"\"\"\n",
        "    As a color expert specializing in the Valspar paint catalog:\n",
        "\n",
        "    I need to identify the 3 closest matches in the Valspar paint collection to a specific color:\n",
        "    - RGB: ({rgb_values[0]}, {rgb_values[1]}, {rgb_values[2]})\n",
        "    - HEX: {hex_color}\n",
        "\n",
        "    Please analyze this color and identify the closest Valspar paint colors by comparing RGB values and visual similarity.\n",
        "\n",
        "    For the 3 closest matching Valspar colors, provide:\n",
        "    1. Color Name\n",
        "    2. Color Code/Number\n",
        "    3. RGB Values (provide exact numbers)\n",
        "    4. HEX Code\n",
        "    5. Brief Description (texture, mood, common uses)\n",
        "    6. Similarity Score (1-10, with 10 being identical)\n",
        "\n",
        "    Format each match clearly with all details in a consistent structure.\n",
        "\n",
        "    Important: Only include real, currently available Valspar colors with accurate information from their catalog. Do not invent colors or data.\n",
        "    \"\"\"\n",
        "\n",
        "    # API call\n",
        "    print(\"Requesting color matching from Gemini API...\")\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        result = response.text\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"Error during Gemini API call: {e}\")\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Function to create color sample image\n",
        "def create_color_sample(rgb_values, size=(200, 100)):\n",
        "    \"\"\"Create a color sample image from RGB values.\"\"\"\n",
        "    rgb_values = np.clip(rgb_values, 0, 255).astype(np.uint8)\n",
        "    color = tuple(rgb_values)\n",
        "    img = PILImage.new('RGB', size, color)\n",
        "    return img\n",
        "\n",
        "# Function to display Valspar color matches\n",
        "def display_valspar_matches(rgb_values, gemini_response):\n",
        "    \"\"\"Display Gemini API response with visualization.\"\"\"\n",
        "    # Show original color\n",
        "    original_color = create_color_sample(rgb_values)\n",
        "\n",
        "    # Create result container\n",
        "    display(HTML(\"<h2>Original Color</h2>\"))\n",
        "    display(HTML(f\"<p>RGB: ({rgb_values[0]}, {rgb_values[1]}, {rgb_values[2]}), HEX: {rgb_to_hex(rgb_values)}</p>\"))\n",
        "    display(original_color)\n",
        "\n",
        "    # Show Gemini response\n",
        "    display(HTML(\"<h2>Valspar Color Matching Results</h2>\"))\n",
        "    display(HTML(f\"<pre>{gemini_response}</pre>\"))\n",
        "\n",
        "# Function to explain input format\n",
        "def explain_input_format():\n",
        "    \"\"\"Explain the input format.\"\"\"\n",
        "    print(\"Input format: 12 RGB values (3 values × 4 colors = 12 values)\")\n",
        "    print(\"\\nValue order:\")\n",
        "    print(\"1-3: Observed RGB values (observed_R, observed_G, observed_B)\")\n",
        "    print(\"4-6: Reference red RGB values (red_R, red_G, red_B)\")\n",
        "    print(\"7-9: Reference green RGB values (green_R, green_G, green_B)\")\n",
        "    print(\"10-12: Reference blue RGB values (blue_R, blue_G, blue_B)\")\n",
        "    print(\"\\nExample: [150, 100, 80, 230, 50, 35, 120, 250, 80, 0, 0, 250]\")\n",
        "\n",
        "# Main execution code\n",
        "def main():\n",
        "    # Check Gemini API key\n",
        "    if GEMINI_API_KEY == \"YOUR_GEMINI_API_KEY\":\n",
        "        print(\"Please enter your Gemini API key:\")\n",
        "        api_key = input()\n",
        "        genai.configure(api_key=api_key)\n",
        "\n",
        "    # Set model paths\n",
        "    model_dir = '/content/drive/MyDrive/2025_COSI_149B_Project1/Teamwork/output/model/added_data/fianl_color_model_alpha0.2_b32_beta0.5_dec2_drop10_e32_enc3_gamma0.3_lat256_losscomposite_lr0.005_20250322_2225/model_e32_b32_lr0.005_lat256.pt'\n",
        "    scaler_path = '/content/drive/MyDrive/2025_COSI_149B_Project1/Teamwork/output/model/added_data/fianl_color_model_alpha0.2_b32_beta0.5_dec2_drop10_e32_enc3_gamma0.3_lat256_losscomposite_lr0.005_20250322_2225/scalers_e32_b32_lr0.005_lat256.pkl'\n",
        "\n",
        "    # Load model\n",
        "    print(\"Loading model...\")\n",
        "    try:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model, X_scaler, y_scaler = load_model(model_dir, scaler_path, device)\n",
        "        print(f\"Model loaded successfully. Using device: {device}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        print(\"\\nPlease check the model and scaler paths.\")\n",
        "        return\n",
        "\n",
        "    # Explain input format\n",
        "    explain_input_format()\n",
        "\n",
        "    # Process user input\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"\\nEnter 12 RGB values (comma-separated, or 'q' to quit): \")\n",
        "\n",
        "            if user_input.lower() == 'q':\n",
        "                break\n",
        "\n",
        "            # Process input\n",
        "            input_values = [float(x.strip()) for x in user_input.split(',')]\n",
        "\n",
        "            if len(input_values) != 12:\n",
        "                print(f\"Error: 12 values required. Currently {len(input_values)} values entered.\")\n",
        "                continue\n",
        "\n",
        "            # Predict\n",
        "            predicted_color = predict_color(model, X_scaler, y_scaler, input_values, device)\n",
        "\n",
        "            # Output results\n",
        "            rgb_values = np.clip(predicted_color[0], 0, 255).astype(int)\n",
        "            print(f\"\\nPredicted Color RGB: ({rgb_values[0]}, {rgb_values[1]}, {rgb_values[2]})\")\n",
        "\n",
        "            # Visualization\n",
        "            visualize_prediction(input_values, predicted_color)\n",
        "\n",
        "            # Valspar color matching\n",
        "            match_valspar = 'y'\n",
        "            if match_valspar.lower() == 'y':\n",
        "                valspar_matches = find_valspar_color(rgb_values)\n",
        "                display_valspar_matches(rgb_values, valspar_matches)\n",
        "\n",
        "        except ValueError as e:\n",
        "            print(f\"Input error: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error during prediction: {e}\")\n",
        "\n",
        "# Run example\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "FS7xJEQzm0mU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Input from Dict"
      ],
      "metadata": {
        "id": "pBQq8e4rmt3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define rgb_dict (at the top of the file)\n",
        "rgb_dict = {\n",
        "    'circle_2.jpg': np.array([144.63, 39.627, 33.627]),\n",
        "    'triangle_4.jpg': np.array([13.178, 82.888, 48.987]),\n",
        "    'paint-color_1.jpg': np.array([194.97, 183.97, 165.97]),\n",
        "    'pentagon_0.jpg': np.array([11.678, 39.77, 92.407])\n",
        "}"
      ],
      "metadata": {
        "id": "ihrEjv7dmloO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZR8qsfSmYIP"
      },
      "outputs": [],
      "source": [
        "# Enter Gemini API key\n",
        "GEMINI_API_KEY = input('Enter Gemini API:')\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Model-related classes and functions\n",
        "class ColorDataset(Dataset):\n",
        "    def __init__(self, X, y=None):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32) if y is not None else None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.y is not None:\n",
        "            return self.X[idx], self.y[idx]\n",
        "        return self.X[idx]\n",
        "\n",
        "# Function to create dynamic encoder layers\n",
        "def create_encoder_layers(input_dim, hidden_dims, dropout_rate):\n",
        "    layers = []\n",
        "    in_features = input_dim\n",
        "    for hidden_dim in hidden_dims:\n",
        "        layers.append(nn.Linear(in_features, hidden_dim))\n",
        "        layers.append(nn.BatchNorm1d(hidden_dim))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(dropout_rate))\n",
        "        in_features = hidden_dim\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# Function to create dynamic decoder layers\n",
        "def create_decoder_layers(latent_dim, hidden_dims, output_dim, dropout_rate):\n",
        "    layers = []\n",
        "    in_features = latent_dim\n",
        "    for hidden_dim in hidden_dims:\n",
        "        layers.append(nn.Linear(in_features, hidden_dim))\n",
        "        layers.append(nn.BatchNorm1d(hidden_dim))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(dropout_rate))\n",
        "        in_features = hidden_dim\n",
        "    # Add output layer\n",
        "    layers.append(nn.Linear(in_features, output_dim))\n",
        "    layers.append(nn.Sigmoid())  # Output in 0~1 range\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# AutoEncoder model class\n",
        "class ColorAutoEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, encoder_hidden_dims, latent_dim, decoder_hidden_dims, output_dim, dropout_rate):\n",
        "        super(ColorAutoEncoder, self).__init__()\n",
        "\n",
        "        # Create encoder\n",
        "        self.encoder_layers = create_encoder_layers(input_dim, encoder_hidden_dims, dropout_rate)\n",
        "        self.latent_layer = nn.Linear(encoder_hidden_dims[-1], latent_dim)\n",
        "        self.latent_activation = nn.ReLU()\n",
        "\n",
        "        # Create decoder\n",
        "        self.decoder = create_decoder_layers(latent_dim, decoder_hidden_dims, output_dim, dropout_rate)\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.encoder_layers(x)\n",
        "        latent = self.latent_activation(self.latent_layer(x))\n",
        "        return latent\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent = self.encode(x)\n",
        "        output = self.decoder(latent)\n",
        "        return output\n",
        "\n",
        "# Function to load trained model\n",
        "def load_model(model_path, scaler_path, device='cpu'):\n",
        "    \"\"\"Load the trained model and scalers.\"\"\"\n",
        "    # Load scalers\n",
        "    with open(scaler_path, 'rb') as f:\n",
        "        scalers = pickle.load(f)\n",
        "    X_scaler = scalers['X_scaler']\n",
        "    y_scaler = scalers['y_scaler']\n",
        "\n",
        "    # Load model checkpoint\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    model_params = checkpoint['model_params']\n",
        "\n",
        "    # Extract model configuration parameters\n",
        "    latent_dim = model_params['lat']\n",
        "    encoder_layers = model_params['enc']\n",
        "    decoder_layers = model_params['dec']\n",
        "    dropout_rate = model_params['drop'] / 100.0\n",
        "\n",
        "    # Configure hidden layers\n",
        "    encoder_hidden_dims = [128, 64] if encoder_layers == 2 else [128, 64, 32]\n",
        "    decoder_hidden_dims = [64, 128] if decoder_layers == 2 else [32, 64, 128]\n",
        "\n",
        "    # Initialize model\n",
        "    input_dim = 12  # 4 colors * RGB\n",
        "    output_dim = 3  # RGB\n",
        "\n",
        "    model = ColorAutoEncoder(\n",
        "        input_dim,\n",
        "        encoder_hidden_dims,\n",
        "        latent_dim,\n",
        "        decoder_hidden_dims,\n",
        "        output_dim,\n",
        "        dropout_rate\n",
        "    )\n",
        "\n",
        "    # Load saved weights\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    return model, X_scaler, y_scaler\n",
        "\n",
        "# Function to predict color\n",
        "def predict_color(model, X_scaler, y_scaler, input_values, device='cpu'):\n",
        "    \"\"\"Predict color based on input values.\"\"\"\n",
        "    # Check input format\n",
        "    if isinstance(input_values, list) and len(input_values) == 12:\n",
        "        input_array = np.array([input_values])\n",
        "    elif isinstance(input_values, np.ndarray) and input_values.shape[-1] == 12:\n",
        "        if input_values.ndim == 1:\n",
        "            input_array = input_values.reshape(1, -1)\n",
        "        else:\n",
        "            input_array = input_values\n",
        "    else:\n",
        "        raise ValueError(\"Input must be a list with 12 values or a numpy array of shape (N, 12).\")\n",
        "\n",
        "    # Scale input\n",
        "    input_scaled = X_scaler.transform(input_array)\n",
        "    input_tensor = torch.tensor(input_scaled, dtype=torch.float32).to(device)\n",
        "\n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        output_scaled = model(input_tensor).cpu().numpy()\n",
        "\n",
        "    # Inverse scaling\n",
        "    output = y_scaler.inverse_transform(output_scaled)\n",
        "\n",
        "    return output\n",
        "\n",
        "# Function to visualize color prediction\n",
        "def visualize_prediction(input_values, predicted_color, title=None):\n",
        "    \"\"\"Visualize the predicted color.\"\"\"\n",
        "    # Clip RGB values to 0-255 range\n",
        "    predicted_rgb = np.clip(predicted_color[0], 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Normalize RGB values to 0-1 range\n",
        "    predicted_rgb_norm = predicted_rgb / 255.0\n",
        "\n",
        "    # Visualization\n",
        "    fig, ax = plt.subplots(figsize=(6, 3))\n",
        "    ax.add_patch(plt.Rectangle((0, 0), 1, 1, color=predicted_rgb_norm))\n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    else:\n",
        "        plt.title(f\"Predicted Color RGB: ({predicted_rgb[0]}, {predicted_rgb[1]}, {predicted_rgb[2]})\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return predicted_rgb\n",
        "\n",
        "# Function to convert RGB to HEX\n",
        "def rgb_to_hex(rgb):\n",
        "    return '#{:02x}{:02x}{:02x}'.format(int(rgb[0]), int(rgb[1]), int(rgb[2]))\n",
        "\n",
        "# Function to find matching Valspar colors using Gemini API\n",
        "def find_valspar_color(rgb_values):\n",
        "    \"\"\"\n",
        "    Use Gemini API to find closest matching Valspar colors.\n",
        "    \"\"\"\n",
        "    # Convert RGB values to HEX code\n",
        "    hex_color = rgb_to_hex(rgb_values)\n",
        "\n",
        "    # Set up Gemini model\n",
        "    model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "\n",
        "    # Create prompt\n",
        "    prompt = f\"\"\"\n",
        "    As a color expert specializing in the Valspar paint catalog:\n",
        "\n",
        "    I need to identify the 3 closest matches in the Valspar paint collection to a specific color:\n",
        "    - RGB: ({rgb_values[0]}, {rgb_values[1]}, {rgb_values[2]})\n",
        "    - HEX: {hex_color}\n",
        "\n",
        "    Please analyze this color and identify the closest Valspar paint colors by comparing RGB values and visual similarity.\n",
        "\n",
        "    For the 3 closest matching Valspar colors, provide:\n",
        "    1. Color Name\n",
        "    2. Color Code/Number\n",
        "    3. RGB Values (provide exact numbers)\n",
        "    4. HEX Code\n",
        "    5. Brief Description (texture, mood, common uses)\n",
        "    6. Similarity Score (1-10, with 10 being identical)\n",
        "\n",
        "    Format each match clearly with all details in a consistent structure.\n",
        "\n",
        "    Important: Only include real, currently available Valspar colors with accurate information from their catalog. Do not invent colors or data.\n",
        "    \"\"\"\n",
        "\n",
        "    # API call\n",
        "    print(\"Requesting color matching from Gemini API...\")\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        result = response.text\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"Error during Gemini API call: {e}\")\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Function to create color sample image\n",
        "def create_color_sample(rgb_values, size=(200, 100)):\n",
        "    \"\"\"Create a color sample image from RGB values.\"\"\"\n",
        "    rgb_values = np.clip(rgb_values, 0, 255).astype(np.uint8)\n",
        "    color = tuple(rgb_values)\n",
        "    img = PILImage.new('RGB', size, color)\n",
        "    return img\n",
        "\n",
        "# Function to display Valspar color matches\n",
        "def display_valspar_matches(rgb_values, gemini_response):\n",
        "    \"\"\"Display Gemini API response with visualization.\"\"\"\n",
        "    # Show original color\n",
        "    original_color = create_color_sample(rgb_values)\n",
        "\n",
        "    # Create result container\n",
        "    display(HTML(\"<h2>Predicted Original Color</h2>\"))\n",
        "    display(HTML(f\"<p>RGB: ({rgb_values[0]}, {rgb_values[1]}, {rgb_values[2]}), HEX: {rgb_to_hex(rgb_values)}</p>\"))\n",
        "    display(original_color)\n",
        "\n",
        "    # Show Gemini response\n",
        "    display(HTML(\"<h2>Valspar Color Matching Result</h2>\"))\n",
        "    display(HTML(f\"<pre>{gemini_response}</pre>\"))\n",
        "\n",
        "# Function to explain input format\n",
        "def explain_input_format():\n",
        "    \"\"\"Explain the input format.\"\"\"\n",
        "    print(\"Input format: 12 RGB values (3 values × 4 colors = 12 values)\")\n",
        "    print(\"\\nValue order:\")\n",
        "    print(\"1-3: Observed RGB values (observed_R, observed_G, observed_B)\")\n",
        "    print(\"4-6: Reference red RGB values (red_R, red_G, red_B)\")\n",
        "    print(\"7-9: Reference green RGB values (green_R, green_G, green_B)\")\n",
        "    print(\"10-12: Reference blue RGB values (blue_R, blue_G, blue_B)\")\n",
        "\n",
        "# Function to process rgb_dict - only process paint-color_1.jpg as the observed color, use others as reference\n",
        "def process_rgb_dict(rgb_dict, model, X_scaler, y_scaler, device='cpu'):\n",
        "    \"\"\"Process only paint-color_1.jpg from rgb_dict and use others as reference colors.\"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # Extract reference colors\n",
        "    red_reference = rgb_dict.get('circle_2.jpg', np.array([255, 0, 0]))  # Red reference\n",
        "    green_reference = rgb_dict.get('triangle_4.jpg', np.array([0, 255, 0]))  # Green reference\n",
        "    blue_reference = rgb_dict.get('pentagon_0.jpg', np.array([0, 0, 255]))  # Blue reference\n",
        "\n",
        "    # Process only paint-color_1.jpg as observed color\n",
        "    if 'paint-color_1.jpg' in rgb_dict:\n",
        "        observed_color = rgb_dict['paint-color_1.jpg']\n",
        "\n",
        "        # Create input vector with 12 values (observed color + 3 reference colors)\n",
        "        input_values = np.concatenate([\n",
        "            observed_color,\n",
        "            red_reference,\n",
        "            green_reference,\n",
        "            blue_reference\n",
        "        ])\n",
        "\n",
        "        # Predict color\n",
        "        predicted_color = predict_color(model, X_scaler, y_scaler, input_values, device)\n",
        "\n",
        "        # Save results\n",
        "        rgb_values = np.clip(predicted_color[0], 0, 255).astype(int)\n",
        "        results['paint-color_1.jpg'] = {\n",
        "            'input': observed_color,\n",
        "            'predicted': rgb_values,\n",
        "            'hex': rgb_to_hex(rgb_values)\n",
        "        }\n",
        "\n",
        "        # Visualization\n",
        "        print(f\"paint-color_1.jpg\")\n",
        "        print(f\"Observed RGB: ({observed_color[0]}, {observed_color[1]}, {observed_color[2]})\")\n",
        "        print(f\"Predicted RGB: ({rgb_values[0]}, {rgb_values[1]}, {rgb_values[2]})\")\n",
        "        visualize_prediction(input_values, predicted_color, title=\"paint-color_1.jpg Color Prediction\")\n",
        "\n",
        "        # Valspar color matching\n",
        "        try:\n",
        "            valspar_matches = find_valspar_color(rgb_values)\n",
        "            display_valspar_matches(rgb_values, valspar_matches)\n",
        "        except Exception as e:\n",
        "            print(f\"Error during Valspar matching: {e}\")\n",
        "    else:\n",
        "        print(\"paint-color_1.jpg not found in rgb_dict.\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Main execution code\n",
        "def main():\n",
        "    # Check Gemini API key\n",
        "    if GEMINI_API_KEY == \"YOUR_GEMINI_API_KEY\":\n",
        "        print(\"Please enter your Gemini API key:\")\n",
        "        api_key = input()\n",
        "        genai.configure(api_key=api_key)\n",
        "\n",
        "    # Set model paths\n",
        "    model_dir = '/content/drive/MyDrive/2025_COSI_149B_Project1/Teamwork/output/model/added_data/fianl_color_model_alpha0.2_b32_beta0.5_dec2_drop10_e32_enc3_gamma0.3_lat256_losscomposite_lr0.005_20250322_2225/model_e32_b32_lr0.005_lat256.pt'\n",
        "    scaler_path = '/content/drive/MyDrive/2025_COSI_149B_Project1/Teamwork/output/model/added_data/fianl_color_model_alpha0.2_b32_beta0.5_dec2_drop10_e32_enc3_gamma0.3_lat256_losscomposite_lr0.005_20250322_2225/scalers_e32_b32_lr0.005_lat256.pkl'\n",
        "\n",
        "    # Load model\n",
        "    print(\"Loading model...\")\n",
        "    try:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model, X_scaler, y_scaler = load_model(model_dir, scaler_path, device)\n",
        "        print(f\"Model loaded successfully. Using device: {device}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        print(\"\\nPlease check the model and scaler paths.\")\n",
        "        return\n",
        "\n",
        "    # Try to define rgb_dict from user input\n",
        "    try:\n",
        "        # Use rgb_dict already defined at the top of the file\n",
        "        print(\"Using rgb_dict defined in the code.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error defining rgb_dict: {e}\")\n",
        "        print(\"Using externally defined rgb_dict.\")\n",
        "\n",
        "    # Process rgb_dict\n",
        "    print(\"Processing color information from rgb_dict...\")\n",
        "    results = process_rgb_dict(rgb_dict, model, X_scaler, y_scaler, device)\n",
        "\n",
        "    # Results summary\n",
        "    print(\"\\nColor processing complete\")\n",
        "    for color_name, result in results.items():\n",
        "        print(f\"{color_name}: Observed RGB {tuple(result['input'])} → Predicted RGB {tuple(result['predicted'])}\")\n",
        "\n",
        "# Run example\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}